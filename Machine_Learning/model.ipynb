{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "# import sklearn\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "pd.options.display.max_columns = None       # type: ignore\n",
    "pd.set_option('display.precision', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DuckDB database\n",
    "conn = duckdb.connect(database=\"../database/bdt.duckdb\", read_only=False)\n",
    "\n",
    "# Execute SQL query and fetch data into a Pandas DataFrame\n",
    "query = \"SELECT * FROM student_perf\"\n",
    "student_perf_df = conn.execute(query).fetchdf()\n",
    "\n",
    "# Convert the Pandas DataFrame to a Dask DataFrame\n",
    "student_perf_dask = dd.from_pandas(student_perf_df, npartitions=3)\n",
    "\n",
    "# To compute and get the result, you can use compute() method\n",
    "student_perf_dask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_perf_dask.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_perf_dask.describe().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "corr_df = student_perf_dask.drop('AVG_G', axis=1)\n",
    "\n",
    "# plot correlation matrix\n",
    "sns.set_theme(rc={'figure.figsize':(12, 12)})\n",
    "sns.heatmap(corr_df.corr().compute(), annot=True, annot_kws={\"fontsize\":7}, fmt=\".2f\", cmap=\"PiYG\", square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data loading (replace with your actual data)\n",
    "X = student_perf_dask.drop(['passed','AVG_G'], axis=1).compute()\n",
    "y = student_perf_dask['passed'].compute()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=420)\n",
    "\n",
    "# Define the models and their hyperparameters\n",
    "models = {\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(max_iter=1000),\n",
    "        'params': {\n",
    "            'C': [0.01, 0.1, 1, 10, 100],\n",
    "            'solver': ['liblinear']\n",
    "        }\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 10, 20, 30]\n",
    "        }\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'model': GradientBoostingClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'max_depth': [3, 5, 7]\n",
    "        }\n",
    "    },\n",
    "    'SVC': {\n",
    "        'model': SVC(),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'kernel': ['linear', 'rbf']\n",
    "        }\n",
    "    },\n",
    "    'KNeighbors': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'n_neighbors': [3, 5, 7],\n",
    "            'weights': ['uniform', 'distance']\n",
    "        }\n",
    "    },\n",
    "    'NaiveBayes': {\n",
    "        'model': GaussianNB(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'DecisionTree': {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'max_depth': [None, 10, 20, 30]\n",
    "        }\n",
    "    },\n",
    "    'MLPClassifier': {\n",
    "        'model': MLPClassifier(max_iter=1000),\n",
    "        'params': {\n",
    "            'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "            'activation': ['tanh', 'relu'],\n",
    "            'solver': ['adam'],\n",
    "            'momentum': [0.9]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the F1 scorer\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "acc_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# GridSearchCV for each model\n",
    "def evaluate_model(model, params, X_train, y_train, X_test, y_test):\n",
    "    grid_search = GridSearchCV(model, params, cv=5, scoring=f1_scorer)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    return best_model, grid_search.best_params_, grid_search.best_score_, conf_mat\n",
    "\n",
    "# model evaluation\n",
    "results = []\n",
    "for model_name, model_info in models.items():\n",
    "    best_model, best_params, best_score, conf_mat = evaluate_model(model_info['model'], model_info['params'], X_train, y_train, X_test, y_test)\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Best Params': best_params,\n",
    "        'Best F1-Score': best_score,\n",
    "        'Confusion Matrix': conf_mat\n",
    "    })\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Confusion Matrix: {model_name}')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.show()\n",
    "\n",
    "    # save the model\n",
    "    joblib.dump(best_model, f'best_{model_name}_model_without_AVG_G.pkl')\n",
    "\n",
    "# show results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df[['Model', 'Best Params', 'Best F1-Score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data loading (replace with your actual data)\n",
    "X = student_perf_dask.drop('passed', axis=1).compute()\n",
    "y = student_perf_dask['passed'].compute()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=420)\n",
    "\n",
    "# Define the models and their hyperparameters\n",
    "models = {\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(max_iter=1000),\n",
    "        'params': {\n",
    "            'C': [0.01, 0.1, 1, 10, 100],\n",
    "            'solver': ['liblinear']\n",
    "        }\n",
    "    },\n",
    "    'SVC': {\n",
    "        'model': SVC(),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'kernel': ['linear', 'rbf']\n",
    "        }\n",
    "    },\n",
    "    'KNeighbors': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'n_neighbors': [3, 5, 7],\n",
    "            'weights': ['uniform', 'distance']\n",
    "        }\n",
    "    },\n",
    "    'NaiveBayes': {\n",
    "        'model': GaussianNB(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'MLPClassifier': {\n",
    "        'model': MLPClassifier(max_iter=1000),\n",
    "        'params': {\n",
    "            'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "            'activation': ['tanh', 'relu'],\n",
    "            'solver': ['adam'],\n",
    "            'momentum': [0.9]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define the F1 scorer\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "acc_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# GridSearchCV for each model\n",
    "def evaluate_model(model, params, X_train, y_train, X_test, y_test):\n",
    "    grid_search = GridSearchCV(model, params, cv=5, scoring=f1_scorer)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    return best_model, grid_search.best_params_, grid_search.best_score_, conf_mat\n",
    "\n",
    "# model evaluation\n",
    "results = []\n",
    "for model_name, model_info in models.items():\n",
    "    best_model, best_params, best_score, conf_mat = evaluate_model(model_info['model'], model_info['params'], X_train, y_train, X_test, y_test)\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Best Params': best_params,\n",
    "        'Best F1-Score': best_score,\n",
    "        'Confusion Matrix': conf_mat\n",
    "    })\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Confusion Matrix: {model_name}')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.show()\n",
    "\n",
    "    # save the model\n",
    "    joblib.dump(best_model, f'best_{model_name}_model_with_AVG_G.pkl')\n",
    "\n",
    "# show results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df[['Model', 'Best Params', 'Best F1-Score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
